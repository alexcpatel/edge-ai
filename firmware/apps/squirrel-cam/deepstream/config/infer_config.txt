# Model Inference Configuration
#
# To swap models:
#   1. Place ONNX file at /models/<name>.onnx
#   2. Update onnx-file and model-engine-file paths below
#   3. Update num-detected-classes to match your model
#   4. Update labels.txt with your class names (one per line)
#   5. Redeploy - first run converts ONNX to TensorRT engine

[property]
gpu-id=0
net-scale-factor=0.0039215697906911373
model-color-format=0
onnx-file=/models/yolov8n.onnx
model-engine-file=/models/yolov8n.engine
labelfile-path=/config/labels.txt
infer-dims=3;640;640
batch-size=1
network-mode=2
num-detected-classes=80
interval=0
gie-unique-id=1
cluster-mode=2
maintain-aspect-ratio=1
symmetric-padding=1
output-tensor-meta=1

[class-attrs-all]
pre-cluster-threshold=0.25
nms-iou-threshold=0.45
topk=300
